# -*- coding: utf-8 -*-
"""EnsembleModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1En-FsEV6gydjOw_iVMsyzokOCjODwyO9
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import pandas as pd
file_path = r'/content/Nagpur_Daily_2014-04-14_2024-04-14.csv'
data = pd.read_csv(file_path,skiprows=15)
print(data.head(2))
print(data.tail(2))

import seaborn as sns
import matplotlib.pyplot as plt

df_filtered = data.drop(['YEAR', 'MO', 'DY'], axis=1)
correlation_matrix = df_filtered.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Correlation Matrix", fontsize=16)
plt.show()

#correlation of all features with the target variable (assuming 'T2M' is the target)
target_corr = correlation_matrix['T2M'].sort_values(ascending=False)
print("Correlation of features with 'T2M':\n", target_corr)

data.dtypes

data['Date'] = pd.to_datetime(data[['YEAR', 'MO', 'DY']].astype(str).agg('-'.join, axis=1))
print(data.head())

data.dtypes

plt.plot(data['Date'],data['T2M'])
plt.show()

plt.plot(data['Date'],data['PRECTOTCORR'])
plt.show()

plt.plot(data['Date'],data['WS10M'])
plt.show()

plt.plot(data['Date'],data['PS'])
plt.show()

data.fillna(method='ffill', inplace=True)

# Selection features and target variable
X = data[['RH2M', 'WS10M', 'PS']]  # Independent features
y = data['T2M']  # Target variable

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.neural_network import MLPRegressor
from sklearn.ensemble import StackingRegressor

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Random Forest Regressor
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

# Support Vector Machine Regressor (SVR)
svm_model = SVR(kernel='rbf')  # You can try other kernels like 'linear', 'poly', etc.

# Linear Regression
lr_model = LinearRegression()

# Artificial Neural Network (MLPRegressor)
ann_model = MLPRegressor(hidden_layer_sizes=(64, 64), activation='relu', solver='adam', max_iter=500, random_state=42)

# prompt: import r2 score

from sklearn.metrics import r2_score

# Random Forest
rf_model.fit(X_train_scaled, y_train)
rf_pred = rf_model.predict(X_test_scaled)
rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))
rf_r2 = r2_score(y_test, rf_pred)  # R² Score
print(f'Random Forest RMSE: {rf_rmse}, R²: {rf_r2}')

# SVM
svm_model.fit(X_train_scaled, y_train)
svm_pred = svm_model.predict(X_test_scaled)
svm_rmse = np.sqrt(mean_squared_error(y_test, svm_pred))
svm_r2 = r2_score(y_test, svm_pred)  # R² Score
print(f'SVM RMSE: {svm_rmse}, R²: {svm_r2}')

# Linear Regression
lr_model.fit(X_train_scaled, y_train)
lr_pred = lr_model.predict(X_test_scaled)
lr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))
lr_r2 = r2_score(y_test, lr_pred)  # R² Score
print(f'Linear Regression RMSE: {lr_rmse}, R²: {lr_r2}')

# ANN
ann_model.fit(X_train_scaled, y_train)
ann_pred = ann_model.predict(X_test_scaled)
ann_rmse = np.sqrt(mean_squared_error(y_test, ann_pred))
ann_r2 = r2_score(y_test, ann_pred)  # R² Score
print(f'ANN RMSE: {ann_rmse}, R²: {ann_r2}')

# # Stacking Regressor combines predictions from multiple models

# Define the base models
estimators = [
    ('rf', rf_model),
    ('svm', svm_model),
    ('lr', lr_model),
    ('ann', ann_model)
]

# Create the stacking regressor
stacking_model = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())

# Fit the stacking model
stacking_model.fit(X_train_scaled, y_train)

# Make predictions with the stacking model
stacking_pred = stacking_model.predict(X_test_scaled)

# Evaluate the stacking model
stacking_rmse = np.sqrt(mean_squared_error(y_test, stacking_pred))
stacking_r2 = r2_score(y_test, stacking_pred)
print(f'Stacking RMSE: {stacking_rmse}, R²: {stacking_r2}')

# # Stacking Model
# stacking_model.fit(X_train_scaled, y_train)
# stacking_pred = stacking_model.predict(X_test_scaled)
# stacking_rmse = np.sqrt(mean_squared_error(y_test, stacking_pred))
# stacking_r2 = r2_score(y_test, stacking_pred)  # R² Score
# print(f'Stacking Model RMSE: {stacking_rmse}, R²: {stacking_r2}')

# Compare performances
model_performance = pd.DataFrame({
    'Model': ['Random Forest', 'SVM', 'Linear Regression', 'ANN', 'Stacking'],
    'RMSE': [rf_rmse, svm_rmse, lr_rmse, ann_rmse, stacking_rmse],
    'R² Score': [rf_r2, svm_r2, lr_r2, ann_r2, stacking_r2]
})

print(model_performance)

import matplotlib.pyplot as plt
import numpy as np

# Assuming you have true and predicted values
# For example, y_test (true) and pred (predicted)

# Scatter plot for True vs Predicted
plt.figure(figsize=(10,6))
plt.scatter(y_test, rf_pred, color='blue', label='Predicted', alpha=0.6)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', label='Perfect Fit Line', lw=2)  # Reference line for perfect prediction
plt.xlabel('True Temperature')
plt.ylabel('Predicted Temperature')
plt.title('True vs Predicted Temperature (Random Forest)')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10,6))
plt.scatter(y_test, stacking_pred, color='blue', label='Predicted', alpha=0.6)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', label='Perfect Fit Line', lw=2)  # Reference line for perfect prediction
plt.xlabel('True Temperature')
plt.ylabel('Predicted Temperature')
plt.title('True vs Predicted Temperature (Stacking Model)')
plt.legend()
plt.grid(True)
plt.show()

from sklearn.metrics import accuracy_score

def calculate_accuracy(y_true, y_pred, threshold=0.1):
    """Calculates the accuracy of predictions within a given threshold."""
    # Convert predictions to binary format based on the threshold
    y_pred_binary = [1 if abs(y_pred_i - y_true_i) <= threshold else 0 for y_pred_i, y_true_i in zip(y_pred, y_true)]
    y_true_binary = [1] * len(y_true)

    # Calculate the accuracy and adjust to the desired format
    accuracy = accuracy_score(y_true_binary, y_pred_binary)
    return round(accuracy * 10, 1)  # Multiply by 10 and round to 1 decimal place

# Calculating accuracy for different models
rf_accuracy = calculate_accuracy(y_test, rf_pred)
svm_accuracy = calculate_accuracy(y_test, svm_pred)
lr_accuracy = calculate_accuracy(y_test, lr_pred)
ann_accuracy = calculate_accuracy(y_test, ann_pred)
stacking_accuracy = calculate_accuracy(y_test, stacking_pred)

# Add accuracy scores to model_performance
model_performance['Accuracy'] = [rf_accuracy, svm_accuracy, lr_accuracy, ann_accuracy, stacking_accuracy]

# Print the updated model performance
print(model_performance)

# from sklearn.metrics import accuracy_score
# def calculate_accuracy(y_true, y_pred):


#   threshold = 0.1


#   y_pred_binary = [1 if abs(y_pred_i - y_true_i) <= threshold else 0 for y_pred_i, y_true_i in zip(y_pred, y_true)]
#   y_true_binary = [1] * len(y_true)
#   accuracy = accuracy_score(y_true_binary, y_pred_binary)
#   return accuracy

# # Calculating accuracy for different models
# rf_accuracy = calculate_accuracy(y_test, rf_pred)
# svm_accuracy = calculate_accuracy(y_test, svm_pred)
# lr_accuracy = calculate_accuracy(y_test, lr_pred)
# ann_accuracy = calculate_accuracy(y_test, ann_pred)
# stacking_accuracy = calculate_accuracy(y_test, stacking_pred)

# # Add accuracy score to model_performance
# model_performance['Accuracy'] = [rf_accuracy, svm_accuracy, lr_accuracy, ann_accuracy, stacking_accuracy]

# print(model_performance)

# def calculate_accuracy(y_true, y_pred, threshold=0.1):
#   """Calculates the accuracy of predictions within a given threshold."""
#   y_pred_binary = [1 if abs(y_pred_i - y_true_i) <= threshold else 0 for y_pred_i, y_true_i in zip(y_pred, y_true)]
#   y_true_binary = [1] * len(y_true)
#   accuracy = accuracy_score(y_true_binary, y_pred_binary)
#   return accuracy

# # Calculating accuracy for different models
# rf_accuracy = calculate_accuracy(y_test, rf_pred)
# svm_accuracy = calculate_accuracy(y_test, svm_pred)
# lr_accuracy = calculate_accuracy(y_test, lr_pred)
# ann_accuracy = calculate_accuracy(y_test, ann_pred)
# stacking_accuracy = calculate_accuracy(y_test, stacking_pred)

# # Add accuracy score to model_performance
# model_performance['Accuracy'] = [rf_accuracy, svm_accuracy, lr_accuracy, ann_accuracy, stacking_accuracy]

# model_performance

